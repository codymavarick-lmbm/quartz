{"CV":{"slug":"CV","filePath":"CV.md","title":"Curriculum Vitae","links":["/"],"tags":["component"],"content":"← Home"},"Notes/Computational-Statistics/Week-4":{"slug":"Notes/Computational-Statistics/Week-4","filePath":"Notes/Computational-Statistics/Week-4.md","title":"Week 4 - Exact Permutation Tests","links":[],"tags":["component"],"content":"course: “Math 185 – Computational Statistics”\ntags: [statistics, hypothesis-testing, exact-tests, permutation-tests]\nClinical Trials\nClinical trials are research studies performed on people that aim to evaluate medical, surgical, or behavioral interventions. Typical research questions include:\n\n\nIs a new treatment safe and effective?\n\n\nIs a new treatment more effective and/or less harmful than the standard treatment?\n\n\nExample: Response Rate of a New Pain Drug\nSuppose a new pain drug is tested to determine whether the response rate is at least 85%.\nWe test:\nH_0: p = 0.85 \\quad \\text{vs.} \\quad H_1: p \\neq 0.85  \nOne-sided vs Two-sided Tests\nThere is long-standing debate in clinical research regarding whether hypothesis tests should be one-sided or two-sided.\n\n\nOne-sided tests are sometimes argued for when only improvement is of interest.\n\n\nTwo-sided tests account for the possibility that a treatment may perform worse than expected.\n\n\nBecause adverse or unexpected effects are rarely impossible, the modern consensus in medical research favors two-sided hypothesis tests.\n\nExact Binomial Test\nSuppose:\n\n\nn = 19 patients are enrolled\n\n\nX = number of positive responses\n\n\nObserved X = 18\n\n\nUnder the null hypothesis:\nX \\sim \\text{Binomial}(n=19, p=0.85)  \nExact binomial tests are used instead of normal approximations when sample sizes are small or when guarantees on coverage are needed.\n\nExact Confidence Intervals (Clopper–Pearson)\nClopper and Pearson (1934) defined an exact (1-\\alpha) confidence interval for p by inverting two one-sided binomial tests.\nThe interval (p_\\ell, p_u) satisfies:\n\\sum_{k=0}^{x} \\binom{n}{k} p_u^k (1 - p_u)^{n-k} = \\frac{\\alpha}{2}  \n\\sum_{k=x}^{n} \\binom{n}{k} p_\\ell^k (1 - p_\\ell)^{n-k} = \\frac{\\alpha}{2}  \nwith:\n\n\np_\\ell = 0 if x = 0\n\n\np_u = 1 if x = n\n\n\nThis method guarantees at least 1-\\alpha coverage.\n\nTwo-Sample Binomial Problem\nWe compare two treatments:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutcomeControl (0)Treatment (1)TotalSuccessY_0Y_1YFailuren_0-Y_0n_1-Y_1n-YTotaln_0n_1n\nWhere:\nY_0 \\sim \\text{Binomial}(n_0, p_0), \\quad Y_1 \\sim \\text{Binomial}(n_1, p_1)  \nWe test:\nH_0: p_0 = p_1  \n\nFisher’s Exact Test\nFisher’s Tea Drinker Example\nA British woman claimed she could tell whether milk or tea was poured first.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuess \\ TrueMilkTeaTotalMilk314Tea134Total448\nUnder the null hypothesis of independence, the table follows a hypergeometric distribution conditional on the margins.\nP(Y_0 = k) = \\frac{\\binom{n_0}{k} \\binom{n_1}{Y-k}}{\\binom{n}{Y}}  \nThe p-value is computed by summing probabilities of tables that are at least as extreme as the observed one.\nFor this example:\np\\text{-value} = \\frac{\\binom{4}{3}\\binom{4}{1} + \\binom{4}{4}\\binom{4}{0}}{\\binom{8}{4}} \\approx 0.243  \n\nEffect Size Measures\nLet group 0 be the control and group 1 be treated.\n\n\nRisk Difference:\n\\Delta = p_1 - p_0  \n\n\nRisk Ratio (RR):\nRR = \\frac{p_1}{p_0}  \n\n\nOdds Ratio (OR):\nOR = \\frac{p_1(1-p_0)}{p_0(1-p_1)}  \n\n\nProperties:\n\n\np_1 = p_0 \\iff RR = 1 \\iff OR = 1\n\n\nWhen outcomes are rare, OR \\approx RR\n\n\n\nFisher’s Exact Test for r \\times c Tables\nFor an r \\times c contingency table with fixed margins:\nP(K_{11}=k_{11},\\dots,K_{rc}=k_{rc}) = \\frac{\\prod_i R_i! \\prod_j C_j!}{n! \\prod_{i,j} k_{ij}!}  \nA table is considered as extreme if its probability is less than or equal to the observed table’s probability.\nThe number of possible tables grows rapidly with r, c, and n.\n\nPermutation Tests (Two-Sample)\nLet:\nX_1,\\dots,X_n \\sim F_X, \\quad Y_1,\\dots,Y_m \\sim F_Y  \nWe test:\nH_0: F_X = F_Y \\quad \\text{vs.} \\quad H_1: F_X \\succeq F_Y  \nA simple test statistic is:\nT = \\bar X - \\bar Y  \nPermutation Principle\nUnder H_0, the pooled sample\nZ = {X_1,\\dots,X_n, Y_1,\\dots,Y_m}  \nis exchangeable. For any permutation \\pi:\nT_\\pi = T(Z_{\\pi(1)},\\dots,Z_{\\pi(n)}; Z_{\\pi(n+1)},\\dots,Z_{\\pi(n+m)})  \nThe permutation p-value is:\np = \\frac{#{\\pi : T_\\pi \\ge T_{obs}}}{(n+m)!}  \n\nApproximate Permutation Test\nBecause (n+m)! can be enormous, we approximate using B random permutations:\n\n\nCompute T_{obs}\n\n\nFor b = 1,\\dots,B:\n\n\nSample a random permutation \\pi_b\n\n\nCompute T_{\\pi_b}\n\n\n\n\nEstimate:\n\n\n\\hat p = \\frac{#{b : T_{\\pi_b} \\ge T_{obs}} + 1}{B + 1}  \n\nPermutation t-Test\nAssume:\nH_0: \\mu_X = \\mu_Y \\quad \\text{vs.} \\quad H_1: \\mu_X \\neq \\mu_Y  \nwith equal variances.\nThe test statistic:\nT = \\frac{\\bar X - \\bar Y}{s_p\\sqrt{1/n + 1/m}}  \nwhere:\ns_p^2 = \\frac{(n-1)s_X^2 + (m-1)s_Y^2}{n+m-2}  \nIf normality holds:\nT \\sim t_{n+m-2}  \nOtherwise, the permutation distribution provides a valid alternative.\n\nPermutation Tests for Independence\nLet (X_1,Y_1),\\dots,(X_n,Y_n) \\sim F_{X,Y}.\nWe test:\nH_0: F_{X,Y} = F_X F_Y  \nUnder H_0, permuting the Y values breaks any dependence while preserving marginal distributions.\nFor permutation \\pi:\nT_\\pi = T((X_1,Y_{\\pi(1)}),\\dots,(X_n,Y_{\\pi(n)}))  \nThe p-value is:\np = \\frac{#{\\pi : T_\\pi \\ge T_{obs}}}{n!}  \n\nSummary\n\n\nExact tests avoid asymptotic approximations\n\n\nFisher’s exact test conditions on margins\n\n\nPermutation tests rely on exchangeability\n\n\nApproximate permutation tests scale to large samples\n\n\nThese methods are especially valuable in small-sample settings\n\n"},"Projects":{"slug":"Projects","filePath":"Projects.md","title":"Projects","links":["/"],"tags":["component"],"content":"← Home"},"index":{"slug":"index","filePath":"index.md","title":"Emma Hargreaves's Quartz","links":["CV","Projects"],"tags":["component"],"content":"Hello, welcome! I study economics and mathematics with a focus on energy market forecasting and applied econometrics.\n\nCV\nProjects\n"}}